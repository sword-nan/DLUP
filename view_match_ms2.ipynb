{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "sns.set_style('white')\n",
    "colors = sns.color_palette('Set2')\n",
    "\n",
    "def get_matchnum(matched_ms2_metadata):\n",
    "    target_match_num = np.array([], dtype=int)\n",
    "    decoy_match_num = np.array([], dtype=int)\n",
    "\n",
    "    for metadata in matched_ms2_metadata.values():\n",
    "        if metadata['decoy']:\n",
    "            decoy_match_num = np.append(decoy_match_num, len(metadata['candidate_ms2_metadata']['peaks']))\n",
    "        else:\n",
    "            target_match_num = np.append(target_match_num, len(metadata['candidate_ms2_metadata']['peaks']))\n",
    "\n",
    "    return target_match_num, decoy_match_num\n",
    "\n",
    "\n",
    "def plot_match_num(files):\n",
    "    def get_patches(ax: Axes):\n",
    "        # 获取条形图中的条形\n",
    "        patches = [patch for patch in ax.patches if patch.get_height() > 0]\n",
    "\n",
    "        # 获取有效的区间和对应的频数\n",
    "        intervals = []\n",
    "        for patch in patches:\n",
    "            width = patch.get_width()\n",
    "            left = patch.get_x()\n",
    "            label = f'{left:.2f}-{left + width:.2f}'\n",
    "            intervals.append(label)\n",
    "\n",
    "        return patches, intervals\n",
    "    \n",
    "    def set_patches_xtick(ax: Axes, patches, intervals):\n",
    "        # 设置 x 轴刻度\n",
    "        ax.set_xticks([patch.get_x() + patch.get_width() / 2 for patch in patches])\n",
    "        ax.set_xticklabels(intervals, rotation=90)\n",
    "    \n",
    "    def cal_bin_width(ax: Axes, length: int):\n",
    "        print(len(ax.patches), length)\n",
    "        return length / len(ax.patches)\n",
    "    \n",
    "    for file in files:\n",
    "        path = os.path.join(file, end)\n",
    "        \n",
    "        match_num_metadata = np.load(path, allow_pickle=True).item()\n",
    "\n",
    "        axes: Sequence[Sequence[Axes]]\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(5, 2.7), dpi=100, sharex='col')\n",
    "\n",
    "        target_match_num, decoy_match_num = get_matchnum(match_num_metadata)\n",
    "\n",
    "        sns.histplot(target_match_num, ax=axes[0][0], bins='auto', alpha=0.5, color=colors[0])\n",
    "        # target_patches, target_intervals = get_patches(axes[0][0])\n",
    "        sns.histplot(decoy_match_num, ax=axes[0][1], bins='auto', alpha=0.5, color=colors[1])\n",
    "        # decoy_patches, decoy_intervals = get_patches(axes[0][1])\n",
    "\n",
    "        sns.kdeplot(data=target_match_num, fill=True, ax=axes[1][0], color=colors[0])\n",
    "        sns.kdeplot(data=decoy_match_num, fill=True, ax=axes[1][1], color=colors[1])\n",
    "        # set_patches_xtick(axes[1][0], target_patches, target_intervals)\n",
    "        # set_patches_xtick(axes[1][1], decoy_patches, decoy_intervals)\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                axes[i][j].set_yticks([])\n",
    "\n",
    "        handles = [Patch(facecolor=colors[0], alpha=0.5), Patch(facecolor=colors[1], alpha=0.5)]\n",
    "        labels = ['target', 'decoy']\n",
    "        fig.legend(handles=handles, labels=labels, bbox_to_anchor=(0.35, 0.95, 1, 0.1), ncol=2, loc='lower left', frameon=False)\n",
    "        fig.tight_layout()\n",
    "\n",
    "dir = '/data/xp/train_test_data/astral_20231016_300ngPlasmaSample/match_ms2'\n",
    "files = [os.path.join(dir, f) for f in os.listdir(dir)]\n",
    "end = 'collection.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[:20]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[20:40]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[40:60]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[60:80]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[80:100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[100:120]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[120:140]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[140:160]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[160:180]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_match_num(\n",
    "    files[180:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[2], files[22], files[68], files[84], files[114]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看肽段六个离子的 XIC 图像\n",
    "---\n",
    "\n",
    "匹配原则为\n",
    "\n",
    "$$\n",
    "    |mz_1 - mz_2| < \\delta mz_1\n",
    "$$\n",
    "\n",
    "可以自定义查看匹配成功图谱数量为 $N$ 的肽段六个离子的 XIC 图像，需要形成比较明显的色谱峰，图谱数量至少要达到 $10$ 以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "colors = sns.color_palette('Paired')\n",
    "\n",
    "def view_XIC(macth_ms2_metadata, num_matched_ms2: int, is_decoy=False):\n",
    "\n",
    "    def drop_spines(ax: Axes):\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "    def get_ion_label(fragment):\n",
    "        return f'{fragment[0]}{fragment[1]}'\n",
    "\n",
    "    match_num = np.array([])\n",
    "    decoy = np.array([], dtype=bool)\n",
    "\n",
    "    for metadata in macth_ms2_metadata.values():\n",
    "        num = len(metadata['candidate_ms2_metadata']['peaks'])\n",
    "        match_num = np.append(match_num, num)\n",
    "        decoy = np.append(decoy, metadata['decoy'])\n",
    "\n",
    "    array_items = np.array(list(macth_ms2_metadata.items()), dtype=object)\n",
    "    if not is_decoy:\n",
    "        bool_experission = (match_num == num_matched_ms2) & ~decoy\n",
    "    else:\n",
    "        bool_experission = (match_num == num_matched_ms2) & decoy\n",
    "    \n",
    "    print(len(np.nonzero(bool_experission)[0]))\n",
    "\n",
    "    select_indices = np.nonzero(bool_experission)[0][:20]\n",
    "    select_view_metadata = array_items[select_indices]\n",
    "\n",
    "    for modified_peptide, metadata in select_view_metadata:\n",
    "        print(metadata['FeaturedIons'])\n",
    "        modified_peptide = tuple(modified_peptide)\n",
    "        spectrum = metadata['Spectrum']\n",
    "        mz, intensity = spectrum[:, 0], spectrum[:, 1]\n",
    "        rts = metadata['candidate_ms2_metadata']['rt']\n",
    "        peaks = metadata['candidate_ms2_metadata']['peaks']\n",
    "\n",
    "        if not is_decoy:\n",
    "            fragment = metadata['Fragment']\n",
    "            non_match_color = '#b6c9b8' # , '#bae3eb', '#eaeae8'\n",
    "            non_match_ion_handles = []\n",
    "            non_match_ion_labels = []\n",
    "\n",
    "            handles, labels = [], []\n",
    "\n",
    "        view_data = []\n",
    "\n",
    "        for select_ion_index in range(0, 6):\n",
    "            if mz[select_ion_index] == 0:\n",
    "                continue\n",
    "            if not is_decoy:\n",
    "                ion_label = get_ion_label(fragment[select_ion_index])\n",
    "\n",
    "            rt_seq = np.array([])\n",
    "            intensity = np.array([])\n",
    "\n",
    "            for rt, peak in zip(rts, peaks):\n",
    "                peak_intensity = peak[select_ion_index][1]\n",
    "                if peak_intensity > 0:\n",
    "                    intensity = np.append(intensity, peak_intensity)\n",
    "                    rt_seq = np.append(rt_seq, rt)\n",
    "            \n",
    "            if len(intensity) > 0:\n",
    "                view_data.append({\n",
    "                    'x': rt_seq,\n",
    "                    'y': intensity,\n",
    "                    'color': colors[select_ion_index]\n",
    "                })\n",
    "\n",
    "            if not is_decoy:\n",
    "                if len(intensity) == 0:\n",
    "                    non_match_ion_handles.append(Line2D([0], [0], color=non_match_color))\n",
    "                    non_match_ion_labels.append(f'{ion_label}')\n",
    "                else:\n",
    "                    handles.append(Line2D([0], [0], color=colors[select_ion_index]))\n",
    "                    labels.append(f'{ion_label}')\n",
    "        if not is_decoy:\n",
    "            handles.extend(non_match_ion_handles)\n",
    "            labels.extend(non_match_ion_labels)\n",
    "\n",
    "        axes: Sequence[Axes]\n",
    "        fig, axes = plt.subplots(len(view_data), 1, figsize=(5, 5), dpi=300, sharex=True)\n",
    "        \n",
    "        for data, ax in zip(view_data, axes):\n",
    "            sns.lineplot(x=data['x'], y=data['y'], color=data['color'], ax=ax, marker='o', markersize=3)\n",
    "        \"\"\"\n",
    "            bbox_to_anchor 参数 (x, y, width, height)\n",
    "            x, y 表示你基准点的坐标，默认的 loc = 'lower left' 就是图例左下角，它在整个 figure 中的坐标\n",
    "            width: 图例宽度\n",
    "            height: 图例高度\n",
    "        \"\"\"\n",
    "        for ax in axes:\n",
    "            ax.set_yticks([])\n",
    "        for ax in axes:\n",
    "            drop_spines(ax)\n",
    "        if not is_decoy:\n",
    "            axes[0].legend(handles, labels, bbox_to_anchor=(0, 1.02, 1, 0.1),  loc='lower left', mode='expand', borderaxespad=0., frameon=False, ncol=6, alignment='center')\n",
    "        \n",
    "        axes[-1].set_xlabel('Retention Time(min)')\n",
    "\n",
    "        fig.suptitle(f'{modified_peptide[0]}.{modified_peptide[1]}', fontsize=10)\n",
    "        fig.set_edgecolor('black')\n",
    "        fig.set_linewidth(1.0)\n",
    "\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "dir = '/data/xp/train_test_data/astral_20231016_300ngPlasmaSample/match_ms2'\n",
    "\n",
    "files = [os.path.join(dir, f) for f in os.listdir(dir)]\n",
    "file = os.path.join(dir, '20231016_300ngPlasmaSample_7p5min_100um-13cm_P1-46')\n",
    "\n",
    "end = 'collection.npy'\n",
    "\n",
    "path = os.path.join(file, end)\n",
    "\n",
    "data = np.load(path, allow_pickle=True).item()\n",
    "\n",
    "view_XIC(data, 100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "colors = sns.color_palette('Paired')\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "def plot_xic(key, spectrum, fragment, peaks, rts):\n",
    "    def get_ion_label(fragment):\n",
    "        return f'{fragment[0]}{fragment[1]}'\n",
    "    \n",
    "    def drop_spines(ax: Axes):\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "    mz = spectrum[:, 0]\n",
    "    view_data = []\n",
    "    non_match_ion_handles = []\n",
    "    non_match_ion_labels = []\n",
    "    handles = []\n",
    "    labels = []\n",
    "    non_match_color = '#b6c9b8'\n",
    "    for select_ion_index in range(0, 6):\n",
    "        if mz[select_ion_index] == 0:\n",
    "            continue\n",
    "        ion_label = get_ion_label(fragment[select_ion_index])\n",
    "\n",
    "        rt_seq = np.array([])\n",
    "        intensity = np.array([])\n",
    "\n",
    "        for rt, peak in zip(rts, peaks):\n",
    "            peak_intensity = peak[select_ion_index][1]\n",
    "            if peak_intensity > 0:\n",
    "                intensity = np.append(intensity, peak_intensity)\n",
    "                rt_seq = np.append(rt_seq, rt)\n",
    "        \n",
    "        if len(intensity) > 0:\n",
    "            view_data.append({\n",
    "                'x': rt_seq,\n",
    "                'y': intensity,\n",
    "                'color': colors[select_ion_index]\n",
    "            })\n",
    "\n",
    "        if len(intensity) == 0:\n",
    "            non_match_ion_handles.append(Line2D([0], [0], color=non_match_color))\n",
    "            non_match_ion_labels.append(f'{ion_label}')\n",
    "        else:\n",
    "            handles.append(Line2D([0], [0], color=colors[select_ion_index]))\n",
    "            labels.append(f'{ion_label}')\n",
    "    handles.extend(non_match_ion_handles)\n",
    "    labels.extend(non_match_ion_labels)\n",
    "\n",
    "    axes: Sequence[Axes]\n",
    "    fig, axes = plt.subplots(len(view_data), 1, figsize=(6, 5), dpi=300, sharex=True)\n",
    "    \n",
    "    for data, ax in zip(view_data, axes):\n",
    "        sns.lineplot(x=data['x'], y=data['y'], color=data['color'], ax=ax, marker='o', markersize=3)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    for ax in axes:\n",
    "        drop_spines(ax)\n",
    "\n",
    "    axes[0].legend(handles, labels, bbox_to_anchor=(0, 1.02, 1, 0.1),  loc='lower left', mode='expand', borderaxespad=0., frameon=False, ncol=6, alignment='center')\n",
    "\n",
    "    axes[-1].set_xlabel('Retention Time(min)')\n",
    "\n",
    "    fig.set_edgecolor('black')\n",
    "    fig.set_linewidth(1.0)\n",
    "    fig.suptitle(f'{key[0]}.{key[1]}')\n",
    "\n",
    "def get_topN_metadata(data, key, scores_func, n):\n",
    "    metadata = data[key]\n",
    "\n",
    "    peaks = metadata['candidate_ms2_metadata']['peaks']\n",
    "    spectrum = metadata['Spectrum']\n",
    "    rts = metadata['candidate_ms2_metadata']['rt']\n",
    "    ids = metadata['candidate_ms2_metadata']['id']\n",
    "    fragment = metadata['Fragment']\n",
    "    ex_inten = peaks[:, :, 1]\n",
    "    ref_inten = spectrum[:, 1]\n",
    "    cosine_scores = scores_func([ref_inten], ex_inten)[0]\n",
    "    argmax_indices = np.argsort(cosine_scores)[::-1][:n]\n",
    "    argmax_indices_top10 = np.sort(argmax_indices)\n",
    "\n",
    "    return spectrum, fragment, peaks[argmax_indices_top10], rts[argmax_indices_top10], ids[argmax_indices_top10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dir = '/data/xp/train_test_data/astral_20231016_300ngPlasmaSample/match_ms2'\n",
    "file = '20231016_300ngPlasmaSample_7p5min_100um-13cm_P4-22'\n",
    "end = 'collection.npy'\n",
    "file = os.path.join(dir, file, end)\n",
    "data = np.load(file, allow_pickle=True).item()\n",
    "key = ('_ASQSVSSSYLTWYQQKPGQAPR_', 4)\n",
    "\n",
    "print(data[key]['FeaturedIons'])\n",
    "\n",
    "plot_xic(key, data[key]['Spectrum'], data[key]['Fragment'],data[key]['candidate_ms2_metadata']['peaks'], data[key]['candidate_ms2_metadata']['rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dir = '/data/xp/train_test_data/astral_20231016_300ngPlasmaSample/filter_ms2/penalty_MAE_peaksum'\n",
    "file = '20231016_300ngPlasmaSample_7p5min_100um-13cm_P1-46'\n",
    "end = 'collection.npy'\n",
    "file = os.path.join(dir, file, end)\n",
    "\n",
    "data = np.load(file, allow_pickle=True).item()\n",
    "\n",
    "keys = [\n",
    "    ('_YVGGQEHFAHLLILR_', 3), ('_YFIDFVAR_', 2), ('_SSPVVIDASTAIDAPSNLR_', 3), ('_GQGTLSVVTMYHAK_', 2),\n",
    "    ('_EKAEGDVAALNR_', 3), ('_DRDGNTLTYYR_', 3), ('_NTLHLQM[Oxidation (M)]NSLR_', 3), ('_GGPLDGTYR_', 2),\n",
    "    ('_RLGMFNIQHC[Carbamidomethyl (C)]K_', 3), ('_FVTQAEGAK_', 2)   \n",
    "]\n",
    "\n",
    "for key in keys:\n",
    "    plot_xic(key, data[key]['Spectrum'], data[key]['Fragment'],data[key]['filter_ms2_metadata']['peaks'], data[key]['filter_ms2_metadata']['rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "\n",
    "def cosine(A: npt.NDArray, B: npt.NDArray):\n",
    "    norm_A = np.linalg.norm(A, axis=1, keepdims=True)\n",
    "    norm_B = np.linalg.norm(B, axis=1, keepdims=True)\n",
    "    norlize_A = A / norm_A\n",
    "    norlize_B = B / norm_B\n",
    "    return np.dot(norlize_A, norlize_B.T)\n",
    "\n",
    "def MAE(A: npt.NDArray, B: npt.NDArray):\n",
    "    sum_norm_B = B / np.sum(B, axis=1, keepdims=True)\n",
    "    scores = np.zeros((len(A), len(B)))\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(B)):\n",
    "            scores[i, j] = np.sum(np.abs(A[i] - sum_norm_B[j]))\n",
    "    return -scores\n",
    "\n",
    "def penalty_MAE(A: npt.NDArray, B: npt.NDArray):\n",
    "    sum_norm_B = B / np.sum(B, axis=1, keepdims=True)\n",
    "    scores = np.zeros((len(A), len(B)))\n",
    "    sum_norm_B[sum_norm_B == 0] = 1\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(B)):\n",
    "            scores[i, j] = np.sum(np.abs(A[i] - sum_norm_B[j]))\n",
    "    return -scores\n",
    "\n",
    "def peaksum(A: npt.NDArray, B: npt.NDArray):\n",
    "    max_norm_B = B / np.max(B)\n",
    "    scores = np.zeros((len(A), len(B)))\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(B)):\n",
    "            scores[i, j] = np.sum(max_norm_B[j])\n",
    "    return scores\n",
    "\n",
    "def penalty_MAE_peaksum(A: npt.NDArray, B: npt.NDArray):\n",
    "    peaksum_score = peaksum(A, B)\n",
    "    penalty_MAE_score = penalty_MAE(A, B)\n",
    "    return peaksum_score + penalty_MAE_score\n",
    "\n",
    "n = 6\n",
    "\n",
    "for key in keys:\n",
    "    spectrum, fragment, peaks, rts, ids = get_topN_metadata(data, key, cosine, n)\n",
    "    plot_xic(key, spectrum, fragment, peaks, rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    spectrum, fragment, peaks, rts, ids = get_topN_metadata(data, key, MAE, n)\n",
    "    plot_xic(key, spectrum, fragment, peaks, rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    spectrum, fragment, peaks, rts, ids = get_topN_metadata(data, key, penalty_MAE, n)\n",
    "    plot_xic(key, spectrum, fragment, peaks, rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    spectrum, fragment, peaks, rts, ids = get_topN_metadata(data, key, peaksum, n)\n",
    "    plot_xic(key, spectrum, fragment, peaks, rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    spectrum, fragment, peaks, rts, ids = get_topN_metadata(data, key, penalty_MAE_peaksum, n)\n",
    "    plot_xic(key, spectrum, fragment, peaks, rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = '/data/xp/train_test_data/astral_20231016_300ngPlasmaSample/train/identification/cosine/collection.npy'\n",
    "\n",
    "data = np.load(path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.nonzero(data['Mask'] == True)[0]) / len(data['Mask']) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/xp/train_test_data/astral_20231016_300ngPlasmaSample/test/identification/cosine/collection.npy'\n",
    "\n",
    "data1 = np.load(path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dtype = np.dtype([('x', np.float32, (1, 6)), ('y', np.float32, (5, ))])\n",
    "\n",
    "x = np.random.rand(6)\n",
    "y = np.random.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for i in range(10):\n",
    "    d.append(np.array([(x, y)], dtype=dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate(d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235]),\n",
       "       ([[0.48884606, 0.47345838, 0.24402949, 0.6571189 , 0.3344257 , 0.54226094]], [0.2928983 , 0.7954803 , 0.59721065, 0.43082952, 0.85167235])],\n",
       "      dtype=[('x', '<f4', (1, 6)), ('y', '<f4', (5,))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
